
\chapter{Proposta}

\label{cap:proposta}

Tal como descrito no \autoref{cap:literatura}, a construção do teste Wald é baseada nas estimativas de máxima verossimilhança. Porém, ao avaliar a estatística de teste é possível verificar que ela não faz uso explícito da função de verossimilhança, e sim de um vetor de estimativas dos parâmetros e uma matriz de variância e covariância destes parâmetros. Assim, por mais que os McGLMs não sejam ajustados com base na maximização da função de verossimilhança para obtenção dos parâmetros do modelo, o método de estimação apresentado no \autoref{cap:literatura} fornece os componentes necessários para uma adaptação do teste. 

Sendo assim, das três opções clássicas de testes de hipóteses comumente aplicados a problemas de regressão (razão de verossimilhanças, Wald e escore), o teste Wald se torna o mais atrativo no contexto dos McGLMs pois é o mais simples de se adaptar. Outra vantagem do teste Wald em relação a seus concorrentes é que existe a possibilidade de formular hipóteses para testar qualquer valor. Quando se trata dos McGLMs, esta ideia se torna especialmente atrativa pois forncece ferramentas para avaliar os parâmetros de potência.

Quando trabalhamos na classe dos McGLMs estimamos parâmetros de regressão, dispersão e potência. Os parâmetros de regressão são aqueles que associam a variável explicativa à variável resposta, através do estudo destes parâmetros é possível avaliar o efeito da variável explicativa sobre a resposta. Já os parâmetros de dispersão estão associados ao preditor matricial, através destes parâmetros pode-se avaliar o efeito da correlação entre unidades do estudo. E os parâmetros de potência nos fornecem um indicativo de qual distribuição de probabilidade melhor se adequa ao problema de acordo com a função de variância escolhida. 

Com isso, nosso objetivo consiste em adaptar o teste Wald para realização de testes de hipóteses gerais sobre qualquer parâmetro dos McGLMs, sejam eles de regressão, dispersão ou potência. Com base nesta adaptação, temos ainda como objetivo chegar a procedimentos análogos às análises de variância e análises de variâncias multivariadas para parâmetros de regressão e ainda estender o conceito para parâmetros de dispersão. 

Nossa adaptação visa uma de responder questões comuns no contexto de modelagem, como: quais variáveis influenciam a resposta? Existe efeito da estrutura de correlação entre indivíduos no estudo? Qual a distribuição de probabilidade que melhor se adequa ao problema? O efeito de determinada variável é o mesmo independente da resposta? Dentre outras.

Vale ressaltar que por si só, os McGLMs já contornam importantes restrições encontradas nas classes clássicas de modelos, como a impossibilidade de modelar múltiplas respostas e modelar a dependência entre indivíduos. Nossa contribuição vai no sentido de fornecer ferramentas para uma melhor interpretação dos parâmetros estimados e assim extrair mais informações e conclusões a respeito dos problemas modelados através da classe.

\subsection{Hipóteses e estatística de teste}

Considere um McGLM com $h$ parâmetros estimados, sejam eles de regressão, dispersão e potência. Seja $\boldsymbol{L}$ uma matriz de especificação de hipóteses a serem testadas, de dimensão $s \times h$, $\boldsymbol{\theta_{\beta,\tau,p}}$ um vetor de dimensão $h \times 1$ de parâmetros de regressão, dispersão e potência do modelo, $\boldsymbol{c}$ um vetor de dimensão $s \times 1$ com os valores sob hipótese nula. As hipóteses a serem testadas podem ser escritas como:

\begin{equation}
\label{eq:hipoteses_wald}
H_0: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} = \boldsymbol{c} \ vs \ H_1: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} \neq \boldsymbol{c}, 
\end{equation}

\noindent considere $\boldsymbol{\hat\theta_{\beta,\tau,p}}$ um vetor de dimensão $h \times 1$ com todas as estimativas dos parâmetros de regressão, dispersão e potência do modelo e $J_{\boldsymbol{{\beta,\tau,p}}}^{-1}$ a inversa da matriz de informação de Godambe desconsiderando os parâmetros de correlação, de dimensão $h \times h$. A generalização da estatística de teste do teste Wald para verificar a validade de uma hipótese sobre parâmetros de um McGLM fica dada por:

\begin{equation}
W = (\boldsymbol{L\hat\theta_{\beta,\tau,p}} - \boldsymbol{c})^T \ (\boldsymbol{L \ J_{\boldsymbol{{\beta,\tau,p}}}^{-1} \ L^T})^{-1} \ (\boldsymbol{L\hat\theta_{\beta,\tau,p}} - \boldsymbol{c}),
\end{equation}

\noindent em que $W \sim \chi^2_s$, ou seja, independente do número de parâmetros testados, a estatística de teste $W$ é um único valor que segue assintóticamente distribuição $\chi^2$ com graus de liberdade dados pelo número de parâmetros testados, isto é, o número de linhas da matriz $\boldsymbol{L}$, denotado por $s$. 

Cada coluna da matriz $\boldsymbol{L}$ corresponde a um dos $h$ parâmetros do modelo e cada linha a uma hipótese. Sua construção consiste basicamente em preencher a matriz com 0, 1 e eventualmente -1 de tal modo que o produto $\boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}}$ represente corretamente a hipótese de interesse. A correta especificação de $\boldsymbol{L}$ permite testar qualquer parâmetro individualmente ou até mesmo formular hipóteses para diversos parâmetros, sejam eles de regressão, dispersão ou potência. 

Em um contexto prático, após a obtenção das estimativas dos parâmetros do modelo podemos estar interessados em três tipos de hipóteses: a primeira delas diz respeito a quando o interesse está em avaliar se existe evidência que permita afirmar que apenas um único parâmetro é igual a um valor postulado; a segunda delas ocorre quando há interesse em avaliar se existe evidência para afirmar que um conjunto de parâmetros é igual a um vetor de valores postulado; já a terceira hipótese diz respeito a situações em que o analista está interessado em saber se a diferença entre os efeitos de duas variáveis é igual a 0.

Para fins de ilustração dos tipos de hipóteses mencionadas considere a situação em que deseja-se investigar se uma variável numérica $x_1$ possui efeito sobre duas variáveis resposta, denotadas por $Y_1$ e $Y_2$. Para tal tarefa coletou-se uma amostra com $n$ indivíduos e para cada indivíduo observou-se o valor de $x_1$, $Y_1$ e $Y_2$. Com base nos dados coletados ajustou-se um modelo bivariado, com preditor dado por:

\begin{equation}
g_r(\mu_r) = \beta_{r0} + \beta_{r1} x_1,
\end{equation}

\noindent em que o índice $r$ denota a variável resposta, r = 1,2; $\beta_{r0}$ representa o intercepto; $\beta_{r1}$ um parâmetro de regressão associado a uma variável $x_1$. Considere que cada resposta possui apenas um parâmetro de dispersão: $\tau_{r0}$ e que os parâmetros de potência foram fixados. Portanto, trata-se de um problema em que há duas variáveis resposta e apenas uma variável explicativa. Considere que as unidades em estudo são independentes, logo $Z_0 = I$. 

Neste cenário poderiam ser perguntas de interesse: será que a variável $x_1$ tem efeito apenas sobre a primeira resposta? Ou apenas sobre a segunda resposta? Será que a variável $x_1$ possui efeito sobre as duas respostas ao mesmo tempo? Será que o efeito da variável é o mesmo para ambas as respostas? Todas essas perguntas podem ser respondidas através de testes de hipóteses sobre os parâmetros do modelo e especificadas por meio da \autoref{eq:hipoteses_wald}. Nas subseções a seguir são apresentados os elementos para responder cada uma destas perguntas. 

\subsection{Exemplo 1: hipótese de igualdade para um único parâmetro}

Considere o primeiro tipo de hipótese: há interesse em avaliar se existe efeito da variável $x_1$ apenas na primeira resposta. A hipótese pode ser escrita da seguinte forma:

\begin{equation}
H_0: \beta_{11} = 0 \ vs \ H_1: \beta_{11} \neq 0.
\end{equation}

Esta mesma hipótese pode ser reescrita na notação mais conveniente para aplicação da estatística do teste Wald:

\begin{equation}
H_0: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} = \boldsymbol{c} \ vs \ H_1: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} \neq \boldsymbol{c},
\end{equation}

\noindent em que:

\begin{itemize}
  
  \item $\boldsymbol{\theta_{\beta,\tau,p}^T}$ = $\begin{bmatrix} \beta_{10} \  \beta_{11} \ \beta_{20} \ \beta_{21} \ \tau_{11} \ \tau_{21} \end{bmatrix}$.


\item $\boldsymbol{L} = \begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0  \end{bmatrix}.$
 
\item $\boldsymbol{c}$ = $\begin{bmatrix} 0 \end{bmatrix}$, é o valor sob hipótese nula. 

\end{itemize}

Note que o vetor $\boldsymbol{\theta_{\beta,\tau,p}}$ possui seis elementos, consequentemente a matriz $\boldsymbol{L}$ contém seis colunas (uma para cada elemento) e apenas uma linha, pois apenas um único parâmetro está sendo testado. Essa única linha é composta por zeros, exceto a coluna referente ao parâmetro de interesse que recebe 1. É simples verificar que o produto $\boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}}$ representa a hipótese de interesse inicialmente postulada. Com isso, a distribuição assintítica do teste é $\chi^2_1$

\subsection{Exemplo 2: hipótese de igualdade para múltiplos parâmetros}

Suponha agora que o interesse neste problema genérico não é mais testar o efeito da variável explicativa apenas em uma resposta. Suponha que o interesse é avaliar se existe evidência suficiente para afirmar que há efeito da variável explicativa $x_1$ em ambas as respostas simultâneamente. Neste caso teremos que testar 2 parâmetros: $\beta_{11}$, que associa $x_1$ à primeira resposta; e $\beta_{21}$, que associa $x_1$ à segunda resposta. Podemos escrever a hipótese da seguinte forma:

\begin{equation}
H_0: \beta_{r1} = 0 \ vs \ H_1: \beta_{r1} \neq 0,
\end{equation}

\noindent ou, de forma equivalente:

$$
H_0: 
\begin{pmatrix}
\beta_{11} \\ 
\beta_{21}
\end{pmatrix} 
= 
\begin{pmatrix}
0 \\ 
0
\end{pmatrix}
\ vs \ 
H_1: 
\begin{pmatrix}
\beta_{11} \\ 
\beta_{21}
\end{pmatrix} 
\neq
\begin{pmatrix}
0 \\ 
0 
\end{pmatrix}.
$$

A hipótese pode ainda ser reescrita na notação conveniente para o teste Wald:

\begin{equation}
H_0: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} = \boldsymbol{c} \ vs \ H_1: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} \neq \boldsymbol{c},
\end{equation}

\noindent em que:

\begin{itemize}
  
  \item $\boldsymbol{\theta_{\beta,\tau,p}^T}$ = $\begin{bmatrix} \beta_{10} \  \beta_{11} \ \beta_{20} \ \beta_{21} \ \tau_{11} \ \tau_{21} \end{bmatrix}$.


\item $\boldsymbol{L} = \begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \end{bmatrix}$
 
\item $\boldsymbol{c} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$, é o valor sob hipótese nula. 

\end{itemize}

O vetor $\boldsymbol{\theta_{\beta,\tau,p}}$ se mantém com seis elementos e a matriz $\boldsymbol{L}$ com seis colunas. Neste caso estamos testando dois parâmetros, portanto a matriz $\boldsymbol{L}$ possui duas linhas. Novamente, essas linhas são compostas por zeros, exceto nas colunas referentes ao parâmetro de interesse. É simples verificar que o produto $\boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}}$ representa a hipótese de interesse inicialmente postulada. Com isso, a distribuição assintítica do teste é $\chi^2_2$

\subsection{Exemplo 3: hipótese de igualdade de parâmetros}

Suponha que a hipótese de interesse não envolve testar se o valor do parâmetro é igual a um valor postulado mas sim verificar se, no caso deste problema genérico, o efeito da variável $x_1$ é o mesmo independente da resposta. Nesta situação formularíamos uma hipótese de igualdade entre os parâmetros, ou em outros termos, se a diferença dos efeitos é nula:

\begin{equation}
H_0: \beta_{11} - \beta_{21} = 0 \ vs \ H_1: \beta_{11} - \beta_{21} \neq 0,
\end{equation}

\noindent esta hipótese pode ser reescrita na seguinte notação:

$$H_0: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} = \boldsymbol{c} \ vs \ H_1: \boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}} \neq \boldsymbol{c},$$ 

\noindent em que:

\begin{itemize}
  
  \item $\boldsymbol{\theta_{\beta,\tau,p}^T}$ = $\begin{bmatrix} \beta_{10} \  \beta_{11} \ \beta_{20} \ \beta_{21} \ \tau_{11} \ \tau_{21} \end{bmatrix}$.


\item $\boldsymbol{L} = \begin{bmatrix} 0 & 1 & 0 & -1 & 0 & 0  \end{bmatrix}.$
 
\item $\boldsymbol{c}$ = $\begin{bmatrix} 0 \end{bmatrix}$, é o valor sob hipótese nula. 

\end{itemize}

Como existe apenas uma hipótese, a matriz $\boldsymbol{L}$ possui apenas uma linha. Para a matriz $\boldsymbol{L}$ ser corretamente especificada no caso de uma hipótese de igualdade precisamos colocar 1 na coluna referente a um parâmetro, e -1 na coluna referente ao outro parâmetro, de tal modo que o produto $\boldsymbol{L}\boldsymbol{\theta_{\beta,\tau,p}}$ representa a hipótese de interesse inicialmente postulada. Neste caso, a distribuição assintítica do teste é $\chi^2_1$.

Com isso, mostramos como é possível testar qualquer parâmetro de um McGLM seja ele de regressão, dispersão ou potência. É possível testar hipóteses sobre parâmetros individualmente, formular hipóteses para múltiplos parâmetros, formular hipóteses para combinações entre parâmetros e ainda testar valores diferentes de zero. Como explicitado nos exemplos, basta uma correta especificação da matriz $\boldsymbol{L}$. Independente do número de parâmetros testados, a estatística de teste $W$ é um único valor que segue assintóticamente distribuição $\chi^2$ em que os graus de liberdade são dados pelo número de hipóteses, isto é, o número de linhas da matriz $\boldsymbol{L}$, denotado por $s$.

\subsection{ANOVA e MANOVA via teste Wald}



\begin{itemize}
  \item \textbf{Contexto geral de anova e manova via teste wald}
  \item \textbf{Pegar procedimento das anovas no texto em funções implementadas}
  \item \textbf{Acrescentar manova usando produto kronecker e mostrar exemplos da L}
  \item \textbf{}
\end{itemize}

